{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "* Anywhere from 50% to 80% of data science is data cleaning\n",
    "    * of course I hear 70% of statistics are made up on the spot\n",
    "* Dealing with dirty data is a fact of life when doing data intensive research\n",
    "* Especially if you are collecting or creating the data yourself\n",
    "* Fortunately, Pandas is excellent at data cleaning and once you get the hang of it you might even enjoy it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values \n",
    "\n",
    "* One of challenges you may face when working with messy data are *missing* or **null** values \n",
    "* There are multiple conventions for representing null values when doing data science in Python\n",
    "* There is a Pythonic way using the `None` object\n",
    "* There is a Numpy/Pandas-y way using `NaN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### None - Pythonic Missing Data\n",
    "\n",
    "* None is the standard way of representing nothing in plain python\n",
    "* It is useful, but it is also a complex data structure\n",
    "* It can be used in numeric and programmatic contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a numpy array of numbers and a null value represented by None\n",
    "some_numbers = np.array([1,None,3,4])\n",
    "some_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because numpy arrays (and pandas series/columns) all have to be the same data type, it will default to the most expressive and most inefficient data type for the array\n",
    "    * Note:  Pandas will automatically convert `None` to `Nan` so we use `np.array` here\n",
    "* This means any operations running over the array/column/series are going to run slower than they could if the data type was numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of objects and a list of integers\n",
    "# compute their sum and time how long it takes\n",
    "for dtype in ['object','int']:\n",
    "    print(\"data type = \", dtype)\n",
    "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice the integer array was ***a lot*** faster than the object array\n",
    "* Also, the vectorized math operations don't like `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_numbers.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN - Numpy/Pandas-y Missing Numeric data\n",
    "\n",
    "* The Numpy third-party library has a mechanism for representing missing numeric values\n",
    "* Under the hood, NaNs are a standards compliant floating point numbers \n",
    "    * Note for R users: There is no `Null` only `NaN`\n",
    "* This means you can use them with other numeric arrays for fast computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric Pandas Series with a missing value\n",
    "nanny = pd.Series([1, np.nan, 3, 4])\n",
    "nanny.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we can use all the fast and easy computations in Pandas without worring about missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the sum of all the numbers in the Series\n",
    "nanny.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on Null Values\n",
    "\n",
    "* There are four functions in Pandas that are useful for working with missing data\n",
    "* The examples below operate on Series, but they can work on Dataframes as well\n",
    "\n",
    "\n",
    "### Null value functions\n",
    "\n",
    "* `isna()` - Generate a boolean mask of the missing values (can also use `isnull()`)\n",
    "* `notna()` - Do the opposite of `isna()` (can also use `notnull()`\n",
    "* `dropna()` - Create a filtered copy of the data with no null values\n",
    "* `fillna(value)` - Create a copy of the data will null values filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the Series\n",
    "nanny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what values are null\n",
    "nanny.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what values are not null\n",
    "nanny.notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These masks can be used to filter the data and create a view of missing or not missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not super useful in a Series, but handy with Dataframes\n",
    "nanny[nanny.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rather than creating a view, we can create *copies* of the data with the null values removed or filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just get rid of all the null values\n",
    "no_null_nanny = nanny.dropna()\n",
    "no_null_nanny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the null values with zero\n",
    "fill_null_nanny = nanny.fillna(0)\n",
    "fill_null_nanny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the null values with a different value\n",
    "fill_null_nanny = nanny.fillna(999)\n",
    "fill_null_nanny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original nanny Series remains untouched #noreboot\n",
    "# Fran Drescher frowns with dissapointment \n",
    "nanny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These functions work with dataframes as well\n",
    "* But you will need to pay closer attention to what it is doing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nanny = pd.DataFrame([[1, np.nan, 2],\n",
    "                        [2, 3, 5],\n",
    "                        [np.nan, 4, 6]])\n",
    "df_nanny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropping null values with `dropna()` removes the entire axis (row or column) and returns a new copy of the dataframe\n",
    "* You can specify dropping rows or columns with the axis parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna gets rid of rows by default\n",
    "df_nanny.dropna() # axis=\"rows\" or axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the axis=\"columns\" or axis=1 to drop columns\n",
    "df_nanny.dropna(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are a couple other parameters that let you specify other behaviors\n",
    "* Like only dropping rows/columns with all null values or settings a threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with null values in real data\n",
    "\n",
    "* Here is an example of some real data, the diabetes data from week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data file into a Pandas dataframe\n",
    "df = pd.read_csv(\"../2 - data python two/diabetes.csv\")\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the metadata about the data, making sure to display null values\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we look closely at this information we can see there are a few null values in this dataset\n",
    "* There are 403 rows, but some columns have less than 403 non-null values\n",
    "* Now let's check which values in the dataset are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask where True indicates a null value\n",
    "df.isna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gak! Too much data, how can we just get a quick count of the null values?\n",
    "* What if we combined `isnull()` with the `sum()` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sum function to count the True values in the boolean mask\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we wanted to look at a specific column we can do the same operation \n",
    "* These functions work with Series as well as DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many null values in the chol column\n",
    "df[\"chol\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's deal with missing values\n",
    "* Solution 1: Remove rows with empty values\n",
    "* If there are only a few null values and you know that deleting values will not cause adverse effects on your result, remove them from your DataFrame\n",
    "* Make sure to save the new dataframe to a new variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display missing value counts\n",
    "print(\"Missing values before dropping rows: \")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# Display new dataset\n",
    "mod_df = df.dropna() # make a copy of the dataframe with null values removed\n",
    "print(\"Missing values after dropping rows: \")\n",
    "print(mod_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "A reviewer on your article that you submitted to the most prestigious journal in your field, loves your analysis but doesn't like the fact you dropped rows with missing cholesterol values. You can't drop them and you can't just put in zero, so you need to identify a technique to deal with those missing values; some kind of *interpolation* that *fills in* a new value in place of the null values. Hopefully it won't drastically change the interpretation!\n",
    "\n",
    "1. Create a new `filler_value` by deriving a number (mean, median or something else) from the column of cholesterol values (`df['chol']`)\n",
    "2. Use the `fillna()` function to fill in the missing values of the cholesterol column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "\n",
    "## Create a filler value\n",
    "filler_value = ???\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "* One quick and easy way is to fill in missing values with the mean value of a giving column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean\n",
    "filler_value = df[\"chol\"].mean()\n",
    "filler_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill missing values with a mean (average) value of a given column\n",
    "# Note the inplace=True parameter - that means that we are overwriting the data\n",
    "# in the existing dataset\n",
    "df[\"chol\"].fillna(filler_value, inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No more null values in the `chol` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized String Operations\n",
    "\n",
    "* If you are dealing with textual or categorical data, you often have to clean strings\n",
    "* Pandas has a set of *Vectorized String Operations* that are much faster and easier than the Python equivalents \n",
    "* Especially handling bad data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "\n",
    "for s in data:\n",
    "    print(s.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But like above, this breaks very easily with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']\n",
    "\n",
    "for s in data:\n",
    "    print(s.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Pandas library has *vectorized string operations* that handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our list into a Series\n",
    "names = pd.Series(data)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the string vector function to capitalize everything\n",
    "names.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Look ma! No errors!\n",
    "* Pandas includes a a bunch of methods for doing things to strings.\n",
    "\n",
    "|  Functions  |. |.  |. |\n",
    "|-------------|------------------|------------------|------------------|\n",
    "|``len()``    | ``lower()``      | ``translate()``  | ``islower()``    | \n",
    "|``ljust()``  | ``upper()``      | ``startswith()`` | ``isupper()``    | \n",
    "|``rjust()``  | ``find()``       | ``endswith()``   | ``isnumeric()``  | \n",
    "|``center()`` | ``rfind()``      | ``isalnum()``    | ``isdecimal()``  | \n",
    "|``zfill()``  | ``index()``      | ``isalpha()``    | ``split()``      | \n",
    "|``strip()``  | ``rindex()``     | ``isdigit()``    | ``rsplit()``     | \n",
    "|``rstrip()`` | ``capitalize()`` | ``isspace()``    | ``partition()``  | \n",
    "|``lstrip()`` |  ``swapcase()``  |  ``istitle()``   | ``rpartition()`` |\n",
    "\n",
    "### Exercise\n",
    "\n",
    "* In the cells below, try three of the string operations listed above on the Pandas Series `monte`\n",
    "* Remember, you can hit tab to autocomplete and shift-tab to see documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n",
    "                   'Eric Idle', 'Terry Jones', 'Michael Palin'])\n",
    "monte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First\n",
    "monte.str.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second\n",
    "monte.str.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third\n",
    "monte.str.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Vector Operations with Real Data\n",
    "\n",
    "* Let's try some string vector operations using real data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the chipotle data and look at the first 5 rows\n",
    "orders = pd.read_csv(\"../4 - data management one/chipotle.tsv\", sep=\"\\t\")\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have downloaded the data and loaded it into a dataframe directly from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the rows and columns of the dataframe\n",
    "orders.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see there are nearly 4,622 order, and 5 columns.\n",
    "* Let's take a look at the 4th row to see what textual information we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display the first item in the DataFrame\n",
    "orders.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use Vectorized String Operations to explore the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summarize the length of the choice_description string\n",
    "orders['choice_description'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# which row has the longest ingredients string\n",
    "orders['choice_description'].str.len().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use iloc to fetch that specific row from the dataframe\n",
    "orders.iloc[3659]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use iloc to fetch the max row automatically\n",
    "orders.iloc[orders['choice_description'].str.len().idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only look at the description string\n",
    "orders.iloc[orders['choice_description'].str.len().idxmax()]['choice_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* WOW! That is a lot of ingredients! It looks like that string is semi-structured, I wonder if we can do something with it...\n",
    "* We could start by doing some string matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many orders contain salsa\n",
    "orders['choice_description'].str.contains('Salsa').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note, you can use dot notation with column names\n",
    "* This is useful because then you can use autocomplete with the string vector functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many orders contain salsa\n",
    "orders.choice_description.str.contains('Salsa').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many Burritos\n",
    "orders.item_name.str.contains(\"Burrito\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many burritos...capitalization matters!\n",
    "orders.item_name.str.contains(\"burrito\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's find the burrito with the most items in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only look at the description string\n",
    "burrito_mask = orders.item_name.str.contains(\"Burrito\")\n",
    "burrito_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the id of the burrito with the longest description\n",
    "max_burrito_id = orders[burito_mask][\"choice_description\"].str.len().idxmax()\n",
    "max_burrito_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the description column of the row with the max_burrito_id\n",
    "orders.iloc[max_burrito_id][\"choice_description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* That is a LOADED BURRITO!\n",
    "* This data is interesting, but not very useful because it is one big string\n",
    "* But we can probably do more with that `choice_description` column\n",
    "* Let's pretend [it doesn't look like Python code](https://stackoverflow.com/questions/33281450/right-way-to-use-eval-statement-in-pandas-dataframe-map-function) and instead treat it as a comma separated list\n",
    "* What string function could we use?\n",
    "\n",
    "|  Functions  |. |.  |. |\n",
    "|-------------|------------------|------------------|------------------|\n",
    "|``len()``    | ``lower()``      | ``translate()``  | ``islower()``    | \n",
    "|``ljust()``  | ``upper()``      | ``startswith()`` | ``isupper()``    | \n",
    "|``rjust()``  | ``find()``       | ``endswith()``   | ``isnumeric()``  | \n",
    "|``center()`` | ``rfind()``      | ``isalnum()``    | ``isdecimal()``  | \n",
    "|``zfill()``  | ``index()``      | ``isalpha()``    | ``split()``      | \n",
    "|``strip()``  | ``rindex()``     | ``isdigit()``    | ``rsplit()``     | \n",
    "|``rstrip()`` | ``capitalize()`` | ``isspace()``    | ``partition()``  | \n",
    "|``lstrip()`` |  ``swapcase()``  |  ``istitle()``   | ``rpartition()`` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the split function to break up the different  \n",
    "orders.choice_description.str.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But what about those pesky brackets! Let's get rid of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the left brackets\n",
    "orders.choice_description.str.replace(\"[\",\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the left and right brackets\n",
    "orders.choice_description.str.replace(\"[\",\"\" ).str.replace(\"]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the left and right brackets and split on commas\n",
    "orders.choice_description.str.replace(\"[\",\"\" ).str.replace(\"]\",\"\").str.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wait what!? The brackets are back!(*@&#^$\n",
    "* Yes, but now they indicate Python lists instead of `[` and `]` characters (confusing yes I know)\n",
    "* How can we grab items from those lists of ingredients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the left and right brackets and split on commas and grab the first element\n",
    "orders.choice_description.str.replace(\"[\",\"\" ).str.replace(\"]\",\"\").str.split(\",\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the left and right brackets and split on commas and grab the last element\n",
    "orders.choice_description.str.replace(\"[\",\"\" ).str.replace(\"]\",\"\").str.split(\",\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the left and right brackets and split on commas and grab the first 3 elements\n",
    "orders.choice_description.str.replace(\"[\",\"\" ).str.replace(\"]\",\"\").str.split(\",\").str[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the split descriptions into a new Series\n",
    "split_description = orders.choice_description.str.replace(\"[\",\"\" ).str.replace(\"]\",\"\").str.split(\",\")\n",
    "split_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the 4504th element of the split_descriptions series\n",
    "split_description.iloc[4604]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Every item in the series is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many items are in each description list\n",
    "split_description.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_description.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
