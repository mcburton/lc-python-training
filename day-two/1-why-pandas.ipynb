{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing with Python and Pandas Part One\n",
    "\n",
    "\n",
    "## Today's Topics\n",
    "\n",
    "* What/Why Pandas\n",
    "* Data Structures\n",
    "* Loading Data\n",
    "* Basic Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pandas \n",
    "\n",
    "* Pandas is a 3rd-party library for doing data analysis\n",
    "* It is a foundational component of Python data science\n",
    "* Developed by [Wes McKinney](http://wesmckinney.com/pages/about.html) while working in the finance industry, so it has some...warts\n",
    "* Vanilla Python (what we did previously) can do many of the same things, but Pandas does them *faster* and usually in fewer lines of code\n",
    "* To do this, is built on top of another 3rd party library called [numpy](http://www.numpy.org/)\n",
    "    * If you have TONS of numerical data you can use Numpy directly\n",
    "* Pandas gives Python some R like functionality (Dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Pandas?\n",
    "\n",
    "* Pandas provides a powerful set of data structure and functions for working with data.\n",
    "* Once you learn these structures and functions (which takes time) you can begin to quickly ask questions and get answers from data.\n",
    "* Pandas integrates nicely with other libraries in the Python data science ecosysem like:\n",
    "    * [Jupyter Notebooks](http://jupyter.org/) - pretty display of Dataframes as HTML tables\n",
    "    * [Matplotlib](https://matplotlib.org/) - Easy plotting from Dataframes\n",
    "    * [Scikit Learn](http://scikit-learn.org/stable/) - Integrates with the machine learning api\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the CSV file\n",
    "data = pd.read_csv(\"community-center-attendance.csv\", index_col=\"date\", parse_dates=True)\n",
    "\n",
    "# drop the id column because we don't need it\n",
    "data = data.drop(columns=\"_id\")\n",
    "\n",
    "# look at the first ten rows of the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the data look like?\n",
    "data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pivot the data so the center names are columns and each row is the number of people attending that community center per day. This is basically rotating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pivot function to make column values into columns\n",
    "data.pivot(columns=\"center_name\", values=\"attendance_count\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot of NaN, and not the tasty garlicy kind either.\n",
    "\n",
    "We might want to break this apart for each Community Center. We can start by inspecting the number rows per center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows per center and sort the list\n",
    "data.groupby(\"center_name\").count().sort_values(by=[\"attendance_count\"], \n",
    "                                                ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at this visually too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the total attendance\n",
    "data.groupby(\"center_name\").count().sort_values(by=[\"attendance_count\"], \n",
    "                                                ascending=False).plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of community centers that don't have a lot of numbers because either 1) they are not very popular or 2) they don't report their daily attendance (more likely given how man NaNs we saw above).\n",
    "\n",
    "What we will do is create a custom filter function that we will apply to ever row in the dataframe using the [groupby filter function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.filter.html). This is some knarly stuff we are doing here. This isn't the plain old filter function, this is a special filter fuction (part of the groupby functionality) that requires you to create a special function to apply to each row. In our case we will make a little function that takes a value and tests to see if it is create than a threshold value (in our case 1000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function we will use to perform a filtering operation on the data\n",
    "# filter out centers that have less then 1000 total entries\n",
    "def filter_less_than(x, threshold):\n",
    "    if len(x) > threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# use the custom function to filter out rows\n",
    "popular_centers = data.groupby(\"center_name\").filter(filter_less_than, \n",
    "                                                     threshold=1000)\n",
    "# look at what centers are in the data now\n",
    "popular_centers.groupby(\"center_name\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a more meaty subset of the data to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first 5 rows\n",
    "popular_centers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the popular community centers\n",
    "popular_centers.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't the most informative representation of the data. Perhaps we can reshape it to make it more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pivot function to make rows into columns with only the popular community centers\n",
    "pivoted_data = popular_centers.pivot_table(columns=\"center_name\",\n",
    "                                           values=\"attendance_count\", \n",
    "                                           index=\"date\")\n",
    "pivoted_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still NaN-y, but not as bad. Now we can look at the attendance at the more popular community centers over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "pivoted_data.plot(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still pretty messy. Let's look at the cumulative sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cumulative sum for every column and make a chart\n",
    "pivoted_data.cumsum().plot(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Brookline is the winner here, but attendance has tapered off in the past couple years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample and compute the monthly totals for the popular community centers\n",
    "pivoted_data.resample(\"M\").sum().plot(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like monthly is too messy, maybe by year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly resample to monthly, compute the totals, and plot\n",
    "pivoted_data.resample(\"Y\").sum().plot(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
